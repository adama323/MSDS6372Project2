ggsave("heart_disease_probabilities.pdf")
exp(-1.7361+6.2954*0.5)/(1+exp(-1.7361+6.2954*0.5))
exp(0.0956*(55-45))
exp(-2.9278+0.0956*50)/(1+exp(-2.9278+0.0956*50))
exp(0.315)
1/0.315
exp(-0.2)
#DATA entry and EDA.  You guys are familiar with this data set already.  Its the same as the PCA Unit 9 code.
library(ISLR)
dim(Auto)
newAuto<-Auto
#creating binary response for illustration
newAuto$mpg<-factor(ifelse(Auto$mpg>median(Auto$mpg),"High","Low"))
newAuto$cylinders<-factor(newAuto$cylinders)
newAuto$origin<-factor(newAuto$origin)
newAuto$mpg<-relevel(newAuto$mpg, ref = "Low")  #""Yes/1" is high mpg "No/0" is low mpg.  This forces the odds to be what you want it to be.
#
#aggregate is good for summary stats by groups for continous predictors
aggregate(weight~mpg,data=newAuto,summary)
aggregate(displacement~mpg,data=newAuto,summary)
#lets attach newAuto so we don't have to keep writing newAuto$
attach(newAuto)
#Table of counts like proc freq are helpful for categorcal predictors
ftable(addmargins(table(mpg,cylinders)))
#It probably is wise to throw out the 3 and 5 cylinder ones or combine it with
#four or six.  I'll remove to keep it short.
newAuto<-newAuto[-which(cylinders %in% c(3,5)),]
attach(newAuto)
cylinders=factor(cylinders)
levels(cylinders)
ftable(addmargins(table(mpg,origin)))
ftable(addmargins(table(mpg,year)))
#to get proportions that make sense
prop.table(table(mpg,cylinders),2)
prop.table(table(mpg,origin),2)
prop.table(table(mpg,year),2)
#Visualize
plot(mpg~cylinders,col=c("red","blue"))
plot(mpg~origin,col=c("red","blue"))
plot(mpg~year,col=c("red","blue"))
#Visualize
plot(weight~mpg,col=c("red","blue"))
plot(acceleration~mpg,col=c("red","blue"))
plot(displacement~mpg,col=c("red","blue"))
#Examine the correlation between the continous predictors
pairs(newAuto[,3:6])
my.cor<-cor(newAuto[,3:6])
my.cor
pairs(newAuto[,3:6],col=mpg)
#If you have a lot of predictors, heatmap with correlations could
#be helpful to examine redundancy.
library(gplots)
library(ggplot2)
heatmap.2(my.cor,col=redgreen(75),
density.info="none", trace="none", dendrogram=c("row"),
symm=F,symkey=T,symbreaks=T, scale="none")
#Another option here would be to do PCA among the continous predictors to see
#if they seperate out.  Or a heatmap.
pc.result<-prcomp(newAuto[,3:6],scale.=TRUE)
pc.scores<-pc.result$x
pc.scores<-data.frame(pc.scores)
pc.scores$mpg<-newAuto$mpg
#Use ggplot2 to plot the first few pc's
ggplot(data = pc.scores, aes(x = PC1, y = PC2)) +
geom_point(aes(col=mpg), size=1)+
ggtitle("PCA of Auto")
##############################
#Interpretation
#The purpose of this code is to illustrate some basic functionality of logistic regression in R.
#Some of the continuous variables look redundant, but for start we will just include everything.
newAuto<-na.omit(newAuto)
model.main<-glm(mpg ~ cylinders+displacement+horsepower+weight+acceleration+year, data=newAuto,family = binomial(link="logit"))
library(ResourceSelection)
library(car)
#Using this tool, GVIF is the same as VIF for continuous predictors only
#For categorical predictors, the value GVIG^(1/(2*df)) should be squared and interpreted
#as a usuaul vif type metric.The following code can be used to interpret VIFs like we
#discussed in class.
(vif(model.main)[,3])^2
vif(model.main)
#As expected displacement and the other continuous variables have moderately high VIF.  Based on the pairwise scatterplots
#I believe it is clear.  It is also apparent that cylinders is associated with some of the predictors
#as well. Higher cylinders tends to produce higher horsepower.
#Remember we should not only resort to things like VIF, we should look at the output and
#see if things make sense.
attach(newAuto)
prop.table(table(mpg,cylinders),2)
t(aggregate(weight~cylinders,data=newAuto,summary))
t(aggregate(acceleration~cylinders,data=newAuto,summary))
t(aggregate(horsepower~cylinders,data=newAuto,summary))
t(aggregate(displacement~cylinders,data=newAuto,summary))
#Hosmer Lemeshow test for lack of fit.  Use as needed.  The g=10 is an option that deals with the continuous predictors if any are there.
#This should be increased with caution.
hoslem.test(model.main$y, fitted(model.main), g=10)
#Summary of current fit
summary(model.main)
#I'm not aware of a nice little automated way to produce Odds ratio metrics
#like SAS does.  Using the summary coefficients we can generate CI for each one in the table
exp(cbind("Odds ratio" = coef(model.main), confint.default(model.main, level = 0.95)))
#This is due to the fact that cylinders are correlated with everything.  Go back to EDA and verify.  We just don't
#see the VIF's look too suspect.
t(aggregate(horsepower~cylinders,data=newAuto,summary))
plot(horsepower~cylinders,data=newAuto)
#For this scenario it might be helpful to just manually fit some models first.
#If one were to conduct forward selection (see below (NO cv/ test set, just AIC selected)), R would want to keep all of the
#highly correlated predictors in questions and the same interpretation problem occurs.
model.null<-glm(mpg ~ 1, data=newAuto,family = binomial(link="logit"))
#This starts with a null model and then builds up using forward selection up to all the predictors that were specified in my
#main model previously.
step(model.null,
scope = list(upper=model.main),
direction="forward",
test="Chisq",
data=newAuto)
#To deal with the redundamcy, I would throw the cylinder variable out and then see what happens
model.main<-glm(mpg ~ displacement+horsepower+weight+acceleration, data=newAuto,family = binomial(link="logit"))
summary(model.main)
exp(cbind("Odds ratio" = coef(model.main), confint.default(model.main, level = 0.95)))
vif(model.main)
#Residual diagnostics can be obtained using
plot(model.main)
#With a simplistic model with no lack of fit issues, we can beging providing statistical inference if no
#interactions are present
summary(model.main)
#I'm not aware of a nice little automated way to produce Odds ratio metrics
#like SAS does.  Using the summary coefficients we can generate CI for each one in the table
exp(cbind("Odds ratio" = coef(model.main), confint.default(model.main, level = 0.95)))
#Playing around with adding more complexity to see if anything sticks compared to the simpler model
model.complex<-glm(mpg ~ displacement+horsepower+weight+acceleration+horsepower:weight+displacement:horsepower+weight:acceleration, data=newAuto,family = binomial(link="logit"))
step(model.main,
scope = list(upper=model.complex),
direction="forward",
test="Chisq",
data=newAuto)
hoslem.test(model.complex$y, fitted(model.complex), g=10)
summary(glm(mpg ~ displacement+horsepower+weight+acceleration+displacement:horsepower+weight:acceleration, data=newAuto,family = binomial(link="logit")))
library(glmnet)
library(bestglm)
dat.train.x <- model.matrix(mpg~cylinders+displacement+horsepower+weight+acceleration+year+origin-1,newAuto)
dat.train.y<-newAuto[,1]
library(glmnet)
cvfit <- cv.glmnet(dat.train.x, dat.train.y, family = "binomial", type.measure = "class", nlambda = 1000)
plot(cvfit)
coef(cvfit, s = "lambda.min")
#CV misclassification error rate is little below .1
cvfit$cvm[which(cvfit$lambda==cvfit$lambda.min)]
#Optimal penalty
cvfit$lambda.min
#For final model predictions go ahead and refit lasso using entire
#data set
finalmodel<-glmnet(dat.train.x, dat.train.y, family = "binomial",lambda=cvfit$lambda.min)
#Get training set predictions...We know they are biased but lets create ROC's.
#These are predicted probabilities from logistic model  exp(b)/(1+exp(b))
fit.pred <- predict(finalmodel, newx = dat.train.x, type = "response")
#Create ROC curves (Remember if you have a test data set, you can use that to compare models)
library(ROCR)
pred <- prediction(fit.pred[,1], dat.train.y)
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
auc.train <- performance(pred, measure = "auc")
auc.train <- auc.train@y.values
#Plot ROC
plot(roc.perf,main="LASSO")
abline(a=0, b= 1) #Ref line indicating poor performance
text(x = .40, y = .6,paste("AUC = ", round(auc.train[[1]],3), sep = ""))
#In addition to LASSO, if we are concerned that the biased estiamtes
#are affecting our model, we can go back and refit using regular
#regression removing the variables that have no importance.
coef(finalmodel)
olog<-glm(mpg~cylinders+horsepower+weight+year+origin,data=newAuto,family=binomial)
fit.pred <- predict(olog, newx = dat.train.x, type = "response")
pred <- prediction(fit.pred, dat.train.y)
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
auc.train <- performance(pred, measure = "auc")
auc.train <- auc.train@y.values
#Plot ROC
plot(roc.perf,main="Ordingary Logistic")
abline(a=0, b= 1) #Ref line indicating poor performance
text(x = .40, y = .6,paste("AUC = ", round(auc.train[[1]],3), sep = ""))
dat.train.x
summary(olog)
dat.train.y
library(ISLR)
attach(Carseats)
High = ifelse(Sales<=8,"No","Yes")
Carseats = data.frame(Carseats,High)
# Use tree to fit a classification tree in order to predict High using all variables but Sales
tree.carseats = tree(High~.-Sales,Carseats)
library(tree)
install.packages("tree")
library(tree)
# Use tree to fit a classification tree in order to predict High using all variables but Sales
tree.carseats = tree(High~.-Sales,Carseats)
summary(tree.carseats)
# Use tree to fit a classification tree in order to predict High using all variables but Sales
tree.carseats = tree(High~.-Sales,Carseats)
summary(tree.carseats)
str(Carseats)
summary(Carseats)
view(Carseats)
library(tidyverse)
view(Carseats)
str(Carseats)
Carseats$High = as.factor(Carseats$High)
# Use tree to fit a classification tree in order to predict High using all variables but Sales
tree.carseats = tree(High~.-Sales,Carseats)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats,pretty=0)
tree.carseats
tree.carseats
# split dataset
set.seed(2)
train=sample(1:nrow(Carseats),200)
Carseats.test = Carseats[-train,]
High.test = High[-train]
tree.carseats = tree(High~.-Sales,Carseats,subset=train)
tree.pred = predict(tree.carseats,Carseats.test,type="class")
table(tree.pred,High.test)
(104+50)/200
dim(Carseats)
# Next, we consider whether pruning the tree might lead to improved results
set.seed(3)
cv.carseats = cv.tree(tree.carseats, FUN=prune.misclass)
names(cv.carseats)
cv.carseats
par(mfrow=c(1,2))
plot(cv.carseats$size,cv.carseats$dev,type="b")
plot(cv.carseats$k,cv.carseats$dev,type="b")
prune.carseats = prune.misclass(tree.carseats,best=8)
plot(prune.carseats)
test(prune.carseats,pretty=0)
text(prune.carseats,pretty=0)
# How well is this?
tree.pred = predict(prune.carseats,Carseats.test,type="class")
table(tree.pred,High.test)
(89+62)/200
(104+50)/200
library(MASS)
set.seed(1)
train = sample(1:nrow(Boston),nrow(Boston)/2)
tree.boston=tree(medv~.,Boston,subset=train)
summary(tree.boston)
plot(tree.boston)
text(tree.boston,pretty=0)
cv.boston=cv.tree(tree.boston)
plot(cv.boston$size,cv.boston$dev,type="b")
prune.boston=prune.tree(tree.boston,best=5)
plot(prune.boston)
text(prune.boston,pretty=0)
yhat = predict(tree.boston,newdata=Boston[-train,])
boston.test=Boston[-train,"medv"]
plot(yhat,boston.test)
abline(0,1)
mean((yhat-boston.test)^2)
library(randomForest)
set.seed(1)
bag.boston=randomForest(medv~.,data=Boston,subset=train,mtry=13,importance=TRUE)
bag.boston
yhat.bag=predict(bag.boston,newdata=Boston[-train,])
plot(yhat.bag,boston.test)
abline(0,1)
mean((yhat-boston.test)^2)
mean((yhat.bag-boston.test)^2)
rf.boston=randomForest(medv~.,data=Boston,subset=train,mtry=6,importance=TRUE)
yhat.rf=predict(rf.boston,newdata=Boston[-train,])
mean((yhat.rf-boston.test)^2)
importance(rf.boston)
varImpPlot(rf.boston)
library(gbm)
install.packages("gbm")
library(gbm)
dim(train)
dim(Boston)
boost.boston=gbm(medv~.,data=Boston[train,],distribution="gaussian",n.trees=5000,interaction.depth=4)
set.seed(1)
boost.boston=gbm(medv~.,data=Boston[train,],distribution="gaussian",n.trees=5000,interaction.depth=4)
summary(boost.boston)
par(mfrow=c(1,2))
plot(boost.boston,i="rm")
plot(boost.boston,i="lstat")
par(mfrow=c(1,2))
plot(boost.boston,i="rm")
plot(boost.boston,i="lstat")
plot(boost.boston,i="rm")
plot(boost.boston,i="lstat")
par(mfrow=c(1,2))
plot(boost.boston,i="rm")
plot(boost.boston,i="lstat")
yhat.boost = predict(boost.boston,newdata=Boston[-train,],n.trees=5000)
mean((yhat.boost-boston.test)^2)
# Changing the shrinkage parameter
boost.boston=gbm(medv~.,data=Boston[train,],distribution="gaussian",n.trees=5000,interaction.depth=4,shrinkage=-.2,verbose=F)
yhat.boost = predict(boost.boston,newdata=Boston[-train,],n.trees=5000)
mean((yhat.boost-boston.test)^2)
head(yhat.boost)
# Changing the shrinkage parameter
boost.boston=gbm(medv~.,data=Boston[train,],distribution="gaussian",n.trees=5000,interaction.depth=4,shrinkage=0.2,verbose=F)
yhat.boost = predict(boost.boston,newdata=Boston[-train,],n.trees=5000)
mean((yhat.boost-boston.test)^2)
setwd("/Users/mingyang/Desktop/SMU/Applied Statistics/MSDS6372Project2/Adult-Income")
library(tidyverse)
adult = read.csv("adult.data.csv",header=FALSE,sep=",",strip.white=TRUE)
# Assign column names
colnames(adult) <- c(
"age", # continuous
"workclass",# Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked
"fnlwgt", # continous, final weight. In other words, this is the number of people the census believes the entry represents
"education", # Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th,
# Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.education-num: continuous
"education.num", # continuous
"marital.status", # Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.
"occupation",  # Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct,                 # Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces
"relationship", # Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried
"race", # White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black
"sex",   # Female, Male
"capital.gain", # continuous
"capital.loss", # continuous
"hours.per.week", # continuous
"native.country", # United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands
"income" # expects to predict
)
str(adult)
## First, convert "?"s to Not-Known...
adult[adult == "?"] <- "Not-Known"
# Decision is made to delete Not-Known observations under workclass & occupation (based on EDA below)
# 1. workclass and occupation missing values are almost identical - except a few workclass assigned Never-worked has a few Not-Known
# workclass and occupation seem to both being good potential predictors for response income
# Thus decision is made to delete Not-Known under occupation and workclass - restrict our range to only predict observation that has occupation or workclass that is known to us
adult = adult%>% filter(workclass!="Not-Known" & occupation!="Not-Known")
# Reorder education levels for later
edu.levels = factor(c("Preschool","1st-4th","5th-6th","7th-8th","9th","10th","11th","12th","HS-grad","Some-college","Assoc-voc","Assoc-acdm","Bachelors","Masters","Prof-school","Doctorate"))
adult$education <- factor(adult$education, levels = edu.levels)
variables.to.factor = c("workclass","marital.status","occupation","relationship","race","sex","native.country","income")
adult[variables.to.factor] = lapply(adult[variables.to.factor],factor)
# Create variable cp.eover7298 per EDA discovery - capital gain equal or over 7298 - using "No" as reference
adult$cp.eover7298<-factor(ifelse(adult$capital.gain>=7298,"Yes","No"),levels=c("No","Yes"))
summary(adult)
# inporting testing data
adult.test = read.csv("adult.test.csv",header=FALSE,sep=",",strip.white=TRUE)
colnames(adult.test) <- c(
"age", # continuous
"workclass",# Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked
"fnlwgt", # continous, final weight. In other words, this is the number of people the census believes the entry represents
"education", # Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th,
# Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.education-num: continuous
"education.num", # continuous
"marital.status", # Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.
"occupation",  # Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct,                 # Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces
"relationship", # Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried
"race", # White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black
"sex",   # Female, Male
"capital.gain", # continuous
"capital.loss", # continuous
"hours.per.week", # continuous
"native.country", # United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands
"income" # expects to predict
)
## First, convert "?"s to Not-Known...
adult.test[adult.test == "?"] <- "Not-Known"
# Similar decision is made to delete workclass that has Not-Known to utilize both workclass and occupation
adult.test = adult.test %>% filter(workclass!="Not-Known"& occupation!="Not-Known")
adult.test$education <- factor(adult.test$education, levels=edu.levels)
variables.to.factor = c("workclass","marital.status","occupation","relationship","race","sex","native.country","income")
adult.test[variables.to.factor] = lapply(adult.test[variables.to.factor],factor)
# Create variable cp.eover7298 per EDA discovery - capital gain equal or over 7298 - using "No" as reference
adult.test$cp.eover7298<-factor(ifelse(adult.test$capital.gain>=7298,"Yes","No"),levels=c("No","Yes"))
summary(adult.test)
#adult.missing = adult %>% filter_all(any_vars(is.na(.)))
#adult.test.missing = adult.test %>% filter_all(any_vars(is.na(.)))
# Look at missing data
library(naniar)
gg_miss_var(adult)
gg_miss_var(adult.test)
# It will be interesting to first perform a PCA and look at how numeric variables can contribute to predicting the response
reduced<-adult[,-c(2,4,6,7,8,9,10,14,15,16)]
library(GGally)
# education, occupation, and native-country have 15 levels or more - these levels need to be explored individually
# ggpairs(adult,columns=c(1,2,3,5,6,8,9,10,11,12,13),aes(colour=income))
# Comment out due to large run time. See image folder pairsplot1.png
# Blue is >50k, Orange <=50k
# Some workclass, marital.status, relationship, race, sex might be helpful for predicting income based on initial pairs plot
#create temp variable in order to fit lm model to test vif
temp = as.numeric(adult$income)
linear.model = lm(temp~.-income-education.num-occupation,data=adult)
library(car) # where vif lives
summary(linear.model)
vif(linear.model)
# See above result. Since occupation and education.num are creating aliased coefficients in the model they were removed from the  model first
# By looking at the rest of the predictors marital.status has GVIF of 63.54, and relationship has GVIF of 79.49 - these can potentiall have multicollinearity problems
# remove relationship variable see if GVIF gets better
linear.model1 = lm(temp~.-income-education.num-occupation-relationship,data=adult)
vif(linear.model1)
table(marital.status,relationship)
# Although by looking at the table above. It seems Marital status can be helpful in explaining status of a specific relationship status
# So even GVIF is high with them both present, their interaction can be helpful to make a better model
# looks like after relationship is removed marital.status becomes a lot better
# so marital.status and relationship are correlated with each other which also make intuitive sense
# Which variable is more associated with the response though? - try chi-squared test approximation(since dataset is quite large)
attach(adult)
chi.test <- chisq.test(table(income,marital.status))
chi.test
# Extremely small p-value < 2.2e-16 - marital.status and income are strongly associated
chi.test1 <- chisq.test(table(income,relationship))
chi.test1
# About the same levels of association
summary(marital.status)
summary(relationship)
# Can potentially explore either marital.status and relationship to see which one produce better prediction
# Note education.num and education may also be strongly correlated
plot(education.num~education)
# As we can see education.num and education are perfectly correlated with each other - education.num is probably directly derived from education level
# Although the actual education category doesn't assume equal distance between levels - it might be a better predictor overall
# Try getting rid of relationship and education.num and see if occupation is still an issue with GVIF
linear.model2 = lm(temp~.-income-education.num-relationship,data=adult)
summary(linear.model2)
vif(linear.model2)
######## This Code part has been readdressed at the above importing section #############################################
# summary(linear.model2) tells us there might be a perfect correlation between Not-Known between workclass and occupation
# Following code to verify if this is true
#adult.temp = adult %>% filter(workclass=="Not-Known"|occupation=="Not-Known") %>% select(workclass,occupation)
#view(adult.temp)
########################################################################################################################
# There is a perfect correlation existed between missingi values of workclass and occupation in original dataset
summary(workclass)
summary(occupation)
# Take a look at whether workclass and occupation are independent from each other
chi.test2 <- chisq.test(table(occupation,workclass))
chi.test2
# So the two groups aren't independent from each other
# Check whether occupation contribute to predicting response variable
chi.test3 <- chisq.test(table(income,occupation))
chi.test3
# Check whether workclass contribute to predicting response variable
chi.test4 <- chisq.test(table(income,workclass))
chi.test4
# Both occupation and workclass seem to associated strongly with the response(income)
# It is best to go back to restrict our range of occupation and workclass to known only - since we want to use both to predict later on
# Looking at some categoricals predictors against response
ftable(addmargins(table(income,sex))) # sex can be contributing to income
plot(income~sex,col=c("red","blue"))
ftable(addmargins(table(income,workclass)))
plot(income~workclass,col=c("red","blue"))
ftable(addmargins(table(income,education))) # Master, Prof-school, Doctorate all have more people making over 50k
plot(income~education,col=c("red","blue"))
ftable(addmargins(table(income,marital.status)))
plot(income~marital.status,col=c("red","blue"))
ftable(addmargins(table(income,relationship)))
plot(income~relationship,col=c("red","blue"))
addmargins(table(income,occupation))
plot(income~occupation,col=c("red","blue"))
ftable(addmargins(table(income,race)))
plot(income~race,col=c("red","blue"))
addmargins(table(income,native.country))
plot(income~native.country,col=c("red","blue"))
# Do some exploration between continuous variable and categorical predictors
plot(age~education) # Not particularly interesting
# Explore some continuous variables predicting response
plot(age~income,col=c("red","blue")) # Might be a good predictor - mean are slighly different
plot(fnlwgt~income,col=c("red","blue")) # Almost identical between two groups - may not be a good predictor
plot(education.num~income,col=c("red","blue")) # education.num derived from education may be a good predictor if only continuous variable can be used
plot(capital.gain~income,col=c("red","blue")) # There is a floor value of 0 for both groups
plot(capital.loss~income,col=c("red","blue")) #similar to capital gain most values are around 0
plot(hours.per.week~income,col=c("red","blue")) # hours.per.week can potentially be a good predictor since there seem to have a good seperation between mean of the two groups
library(MASS)
library(glmnet)
dat.adult.x <- model.matrix(income~.-1,adult)
dat.adult.y<-adult[,15]
cvfit <- cv.glmnet(dat.adult.x, dat.adult.y, family = "binomial", type.measure = "class", nlambda = 1000)
# Generate ROC curve to find a cutoff to use
library(ROCR)
# Following refit with glm model with the variables turned on - EDA variables we deemed less important
simple.log <- glm(income~age+workclass+education+marital.status+occupation+race+sex+capital.loss+hours.per.week+native.country+cp.eover7298,family="binomial",data=adult)
step.log<-simple.log %>% stepAIC(trace=FALSE)
simple.log1 <- glm(income~age+workclass+education+marital.status+occupation+race+sex+capital.loss+hours.per.week+cp.eover7298,family="binomial",data=adult)
summary(simple.log1)
vif(simple.log1)
exp(cbind("Odds ratio" = coef(simple.log1), confint.default(simple.log1, level = 0.95)))
# Generate ROC curve to find a cutoff to use
library(ROCR)
results.sm1 <-prediction(fit.pred.sm1, adult.test$income,label.ordering=c("<=50K.",">50K."))
roc.sm1 = performance(results.sm1, measure = "tpr", x.measure = "fpr")
plot(roc.sm1,colorize = TRUE)
abline(a=0, b= 1)
auc.sm1 <- performance(results.sm1, measure = "auc")
auc.sm1 <- auc.sm1@y.values
text(x = .40, y = .6,paste("AUC = ", round(auc.sm1[[1]],3), sep = ""))
#Making predictions for simple.log1 for ROC plot
fit.pred.sm1<-predict(simple.log1,newdata=adult.test,type="response")
# Generate ROC curve to find a cutoff to use
library(ROCR)
results.sm1 <-prediction(fit.pred.sm1, adult.test$income,label.ordering=c("<=50K.",">50K."))
roc.sm1 = performance(results.sm1, measure = "tpr", x.measure = "fpr")
plot(roc.sm1,colorize = TRUE)
abline(a=0, b= 1)
auc.sm1 <- performance(results.sm1, measure = "auc")
auc.sm1 <- auc.sm1@y.values
text(x = .40, y = .6,paste("AUC = ", round(auc.sm1[[1]],3), sep = ""))
str(audlt)
str(adult)
#Calculate logistic regression using cut of 0.3 on test set
cutoff<-0.275
class.sm1<-factor(ifelse(fit.pred.sm1>cutoff,">50K.","<=50K."),levels=c("<=50K.",">50K."))
library(caret)
confusionMatrix(class.sm1,adult.test$income)
##################################################################################################
# construct the QDA model
# Fron EDA we know fnlwgt is not helpful in identifying income - will not use it here
# We will use education.num since it is a substitute for education
myqda <- qda(income ~ age + education.num+ capital.gain+capital.loss+hours.per.week, data = adult)
myqda.prd <- predict(myqda, newdata = adult.test)
myqda.posterior <- myqda.prd$posterior[,2]
hist(myqda.posterior)
